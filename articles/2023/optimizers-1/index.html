<!DOCTYPE html>
<html class="not-ready lg:text-base" lang="en-us" style="--bg: #faf8f1">
<head>
<meta charset="utf-8"/>
<meta content="IE=edge" http-equiv="X-UA-Compatible"/>
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<title>Optimizers, Part 1 - Aniruddha Deb</title>
<meta name="theme-color"/>
<meta content="Happy New Year! This is going to was supposed to be a long one, so sit back and grab a chocolate (and preferably view this on your laptop)
Some optimization algorithms. Click on a colour in the legend to hide/show it
Table of Contents Introduction Do Solutions Even Exist? How this guide is structured Gradient Descent Optimizers Stochastic Gradient Descent SGD with Momentum SGD with Nesterov Momentum Putting it all together References and Footnotes Introduction Most supervised learning tasks involve optimizing a loss function, in order to fit the model to the given training data." name="description"/>
<meta content="Aniruddha Deb" name="author"/>
<link as="style" href="https://aniruddhadeb.com/main.min.css" rel="preload stylesheet"/>
<link as="image" href="https://aniruddhadeb.com/theme.svg" rel="preload"/>
<link as="image" href="/pic.png" rel="preload"/>
<link as="image" href="https://aniruddhadeb.com/twitter.svg" rel="preload"/>
<link as="image" href="https://aniruddhadeb.com/github.svg" rel="preload"/>
<link as="image" href="https://aniruddhadeb.com/rss.svg" rel="preload"/>
<script>
MathJax = {
  tex: {
    inlineMath: [['$', '$'], ['\\(', '\\)']],
    processEscapes: true
  },
  svg: {
    fontCache: 'global'
  }
};
</script>
<script async="" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-svg.js" type="text/javascript">
</script>
<link href="https://aniruddhadeb.com/favicon/favicon.ico" rel="icon"/>
<link href="https://aniruddhadeb.com/favicon/apple-touch-icon.png" rel="apple-touch-icon" sizes="180x180"/>
<link href="https://aniruddhadeb.com/favicon/favicon-32x32.png" rel="icon" sizes="32x32" type="image/png"/>
<link href="https://aniruddhadeb.com/favicon/favicon-16x16.png" rel="icon" sizes="16x16" type="image/png"/>
<link href="https://aniruddhadeb.com/favicon/site.webmanifest" rel="manifest"/>
<meta content="Hugo 0.115.1" name="generator"/>
<meta content="Optimizers, Part 1" itemprop="name"/>
<meta content="Happy New Year! This is going to was supposed to be a long one, so sit back and grab a chocolate (and preferably view this on your laptop)
Some optimization algorithms. Click on a colour in the legend to hide/show it
Table of Contents Introduction Do Solutions Even Exist? How this guide is structured Gradient Descent Optimizers Stochastic Gradient Descent SGD with Momentum SGD with Nesterov Momentum Putting it all together References and Footnotes Introduction Most supervised learning tasks involve optimizing a loss function, in order to fit the model to the given training data." itemprop="description"/><meta content="2023-01-02T12:25:00+00:00" itemprop="datePublished"/>
<meta content="2023-01-02T12:25:00+00:00" itemprop="dateModified"/>
<meta content="2202" itemprop="wordCount"/>
<meta content="Programming,Machine Learning,Deep Learning," itemprop="keywords"/>
<meta content="summary" name="twitter:card"/>
<meta content="Optimizers, Part 1" name="twitter:title"/>
<meta content="Happy New Year! This is going to was supposed to be a long one, so sit back and grab a chocolate (and preferably view this on your laptop)
Some optimization algorithms. Click on a colour in the legend to hide/show it
Table of Contents Introduction Do Solutions Even Exist? How this guide is structured Gradient Descent Optimizers Stochastic Gradient Descent SGD with Momentum SGD with Nesterov Momentum Putting it all together References and Footnotes Introduction Most supervised learning tasks involve optimizing a loss function, in order to fit the model to the given training data." name="twitter:description"/>
</head>
<body class="text-black duration-200 ease-out dark:text-white">
<header class="mx-auto flex h-[4.5rem] max-w-4xl px-8 lg:justify-center">
<div class="relative z-50 mr-auto flex items-center">
<a class="-translate-x-[1px] -translate-y-[1px] text-2xl font-semibold" href="https://aniruddhadeb.com">Aniruddha Deb</a>
<div aria-label="Dark" class="btn-dark text-[0] ml-4 h-6 w-6 shrink-0 cursor-pointer [background:url(./theme.svg)_left_center/cover_no-repeat] dark:invert dark:[background-position:right]" role="button"></div>
</div>
<div aria-label="Menu" class="btn-menu relative z-50 -mr-8 flex h-[4.5rem] w-[5rem] shrink-0 cursor-pointer flex-col items-center justify-center gap-2.5 lg:hidden" role="button"></div>
<script>
    
    const htmlClass = document.documentElement.classList;
    setTimeout(() => {
      htmlClass.remove('not-ready');
    }, 10);

    
    const btnMenu = document.querySelector('.btn-menu');
    btnMenu.addEventListener('click', () => {
      htmlClass.toggle('open');
    });

    
    const metaTheme = document.querySelector('meta[name="theme-color"]');
    const lightBg = '#faf8f1'.replace(/"/g, '');
    const setDark = (isDark) => {
      metaTheme.setAttribute('content', isDark ? '#000' : lightBg);
      htmlClass[isDark ? 'add' : 'remove']('dark');
      localStorage.setItem('dark', isDark);
    };

    
    const darkScheme = window.matchMedia('(prefers-color-scheme: dark)');
    if (htmlClass.contains('dark')) {
      setDark(true);
    } else {
      const darkVal = localStorage.getItem('dark');
      setDark(darkVal ? darkVal === 'true' : darkScheme.matches);
    }

    
    darkScheme.addEventListener('change', (event) => {
      setDark(event.matches);
    });

    
    const btnDark = document.querySelector('.btn-dark');
    btnDark.addEventListener('click', () => {
      setDark(localStorage.getItem('dark') !== 'true');
    });
  </script>
<div class="nav-wrapper fixed inset-x-0 top-full z-40 flex h-full select-none flex-col justify-center pb-16 duration-200 dark:bg-black lg:static lg:h-auto lg:flex-row lg:!bg-transparent lg:pb-0 lg:transition-none">
<nav class="lg:ml-12 lg:flex lg:flex-row lg:items-center lg:space-x-6">
<a class="block text-center text-2xl leading-[5rem] lg:text-base lg:font-normal" href="/articles/">Blog</a>
<a class="block text-center text-2xl leading-[5rem] lg:text-base lg:font-normal" href="/publications/">Publications</a>
<a class="block text-center text-2xl leading-[5rem] lg:text-base lg:font-normal" href="/files/cv.pdf">CV</a>
</nav>
<nav class="mt-12 flex justify-center space-x-10 dark:invert lg:ml-12 lg:mt-0 lg:items-center lg:space-x-6">
<a class="h-8 w-8 text-[0] [background:var(--url)_center_center/cover_no-repeat] lg:h-6 lg:w-6" href="https://twitter.com/hairband_dude" rel="me" style="--url: url(./twitter.svg)" target="_blank">
        twitter
      </a>
<a class="h-8 w-8 text-[0] [background:var(--url)_center_center/cover_no-repeat] lg:h-6 lg:w-6" href="https://github.com/Aniruddha-Deb" rel="me" style="--url: url(./github.svg)" target="_blank">
        github
      </a>
<a class="h-8 w-8 text-[0] [background:var(--url)_center_center/cover_no-repeat] lg:h-6 lg:w-6" href="https://aniruddhadeb.com/index.xml" rel="alternate" style="--url: url(./rss.svg)" target="_blank">
        rss
      </a>
</nav>
</div>
</header>
<main class="prose prose-neutral relative mx-auto min-h-[calc(100%-9rem)] max-w-4xl px-8 pb-16 pt-12 dark:prose-invert">
<article>
<header class="mb-16">
<h1 class="!my-0 pb-2.5">Optimizers, Part 1</h1>
<div class="text-sm antialiased opacity-60">
<time>Jan 2, 2023</time>
</div>
</header>
<section><p>Happy New Year! This <strike>is going to</strike> was supposed to be a long
one, so sit back and grab a chocolate (and preferably view this on your laptop)</p>
<center>
<iframe src="/articles/2023/res/intro_plot.html" style="width: 100%; height: 650px; border: 0"></iframe>
<p>Some optimization algorithms. Click on a colour in the legend to hide/show it</p>
</center>
<h1 id="table-of-contents">Table of Contents</h1>
<ol>
<li><a href="#introduction">Introduction</a>
<ul>
<li><a href="#solution-existence">Do Solutions Even Exist?</a></li>
<li><a href="#structure">How this guide is structured</a></li>
</ul>
</li>
<li><a href="#gradient-descent-optimizers">Gradient Descent Optimizers</a>
<ul>
<li><a href="#stochastic-gradient-descent">Stochastic Gradient Descent</a></li>
<li><a href="#sgd-with-momentum">SGD with Momentum</a></li>
<li><a href="#sgd-with-nesterov-momentum">SGD with Nesterov Momentum</a></li>
<li><a href="#gradient-descent-comparision">Putting it all together</a></li>
</ul>
</li>
<li><a href="#refs-and-footnotes">References and Footnotes</a></li>
</ol>
<!--
3. <a href="#adaptive-optimizers">Adaptive Optimizers</a>
    * <a href="#adagrad">AdaGrad</a>
    * <a href="#rmsprop">RMSProp</a>
    * <a href="#rmsprop-with-nesterov-momentum">RMSProp with Nesterov Momentum</a>
    * <a href="#adam">Adam</a>
    * <a href="#nadam-nesterov-adam">NAdam (Nesterov Adam)</a>
    * <a href="#adamw">AdamW</a>
    * <a href="#amsgrad">AMSGrad</a>
    * <a href="#adabound">AdaBound</a>
    * <a href="#adabelief">AdaBelief</a>
4. <a href="#second-order-optimizers">Second Order Optimizers</a>
    * <a href="#newton">Newton</a>
    * <a href="#conjugate-gradients">Conjugate Gradients</a>
        * <a href="#fletcher-reeves">Fletcher-Reeves</a>
        * <a href="#polak-ribiere">Polak-Ribiere</a>
    * <a href="#bfgs">BFGS</a>
    * <a href="#l-bfgs">L-BFGS</a>-->
<h1 id="introduction">Introduction</h1>
<p>Most supervised learning tasks involve optimizing a loss function, in order to
fit the model to the given training data. Of these, the most common is neural
network training: neural networks have millions (even billions) of parameters
which need to be tuned so that the model can predict the right outputs.</p>
<p>Obtaining closed form solutions to neural network problems is more often than
not intractable, and so we perform this optimization algorithmically and
numerically. The main things we look for in an algorithm that optimizes the
loss function are:</p>
<ul>
<li>
<p><strong>It should converge</strong>: Sounds like a no-brainer, but the algorithm should be
able to decide when and where to stop, and to ensure that the location at
which it stops is a local minima.</p>
</li>
<li>
<p><strong>It should converge quickly</strong>: The algorithm should take as few steps as
possible to converge, as every step requires a parameter update, and updating
millions (if not billions) of parameters is inefficient. Therefore, it should
take the optimal steps at every point.</p>
</li>
<li>
<p><strong>It should be able to deal with ambiguity</strong>: Loosely worded, the algorithm
would not have the exact value of the gradient: all the algorithms described
use a batch of samples to obtain an estimate of the gradient, and the
expected value of the gradient obtained should equal the gradient of the
function at this point. The algorithm should be able to converge to a local
minima even if it obtains incorrect gradients at some steps in the process.</p>
</li>
</ul>
<h2 id="solution-existence">Do solutions even exist?</h2>
<p>We can’t really go further without knowing what the loss landscape looks like:
do solutions even exist? How do we visualize a high-dimensional loss landscape?</p>
<p>A few observations about the loss landscape of a neural network from Goodfellow
are:</p>
<ol>
<li>
<p><strong>As dimensionality of the latent space increases, the probability a
critical point is a local minima decreases</strong>. The curvature of a point is
given by the eigenvalues of the hessian: if all the eigenvalues are positive,
the point is a local minima (and the hessian is positive semi-definite), and
the opposite for a local maxima. If we consider a random function, choosing
the sign of the eigenvalue is akin to tossing a coin. Therefore, in
n-dimensional space, if we toss n coins to determine these signs, the
probability that all of them turn up positive is very low. Therefore, high-
dimensional space has more saddle points than local minima/maxima</p>
</li>
<li>
<p><strong>There are several equally good local minima</strong>: because of scale invariance,
if you scale the inputs to a layer down by 10 and multiply the outputs by 10,
then you get the same resultant network. Also, if you switch the position of
two neurons in a layer with each other while maintaining the connections,
you get the same network. These two similarities result in a large number of
similar optima, reaching any one of which will optimize the entire network.</p>
</li>
</ol>
<p>Both of these are in our favour, and show us that reaching a local minima in
high-dimensional space should be sufficient to fit the network. We’ll now take
a look at some algorithms which do this.</p>
<p>As for visualizing the loss landscape, this is significantly trickier to do.
This work by <a href="https://arxiv.org/pdf/1712.09913v3.pdf">Goldstein et al</a> does a
good job of it, but visualizing and comparing the paths taken by optimization
algorithms on this landscape is very difficult: because what we’re seeing is a
projection onto two dimensions, the direction taken by the path need not
correspond to the direction of maximum descent. This repository by <a href="https://github.com/logancyang/loss-landscape-anim">Logan Yang</a>
had a good implementation of this paper, along with traces of the paths taken
by various optimization algorithms showing why we can’t use this to
qualitatively compare different optimization algorithms with each other</p>
<center>
<img src="/articles/2023/res/loss_landscape_goldstein.png" width="800px"/>
<p>The loss landscape of ResNet-56 (source: Goldstein et al)</p>
</center>
<h2 id="structure">How this guide is structured</h2>
<p>While most deep learning problems use a super high-dimensional loss function,
for the purposes of this guide we’ll use a simple 2-D loss function which is
a linear combination of gaussians of the following form
$$\begin{gather}
f(x, y) = se^{-(ax+by+c)^2} \\
\mathcal{L} = \sum_{i=1}^{n} f_i(x, y)
\end{gather}$$</p>
<p>The good thing about gaussians is that they’re easy to differentiate
$$\begin{align}
\frac{\partial f}{\partial x} &amp;= -2a(ax+by+c)f(x,y) \\
\frac{\partial f}{\partial y} &amp;= -2b(ax+by+c)f(x,y) \\
\frac{\partial^2 f}{\partial x^2} &amp;= -2a^2(1 - 2(ax+by+c)^2)f(x,y) \\
\frac{\partial^2 f}{\partial x \partial y} &amp;= -2ab(1 - 2(ax+by+c)^2)f(x,y) \\
\frac{\partial^2 f}{\partial y^2} &amp;= -2b^2(1 - 2(ax+by+c)^2)f(x,y)
\end{align}$$</p>
<p>so all the methods can use the exact gradient/hessian of the loss function
rather than a <em>stochastic</em> one. This is kind of cheating, but since this is a
science experiment, let’s run with it. about this loss func</p>
<p>$s, a, b, c$ are generated uniform randomly from a suitable range, and I played
around manually with this till I got a loss function that looked funky enough
for my needs. We finally use the following loss function, and it’s been
exported to the file <code>func.dill</code> if you want to load it in (use dill to load it,
as there were some errors serializing it via pickle)</p>
<iframe src="/articles/2023/res/loss_fn_interactive.html" style="width: 100%; height: 620px; border: 0"></iframe>
<p>The convergence criterion that’s used for all optimizers is when the gradient norm
is less than 0.05, and all the optimizers are limited to take atmost 1000 steps.</p>
<p>The plots are made in Bokeh/Plotly and are interactive (if you haven’t already
played with the plot we generated in the start). I’ve done my best to be
inspired by <a href="https://distill.pub">Distill</a>, most notably <a href="https://distill.pub/2017/momentum/">Gabriel Goh</a>’s
beautiful, interactive article on momentum.</p>
<h1 id="gradient-descent-optimizers">Gradient Descent Optimizers</h1>
<p>Gradient Descent optimizers converge to a local minimum by simply following the
gradient: there’s no adaptiveness here, and it’s akin to feeling the area
around your feet and just taking a small step in the steepest direction, and
repeating that till you get to the minima. There are a few tricks here and we
take hints from Physics to speed up the convergence, but most of the algorithm
relies on the gradient, and the speed with which we’re already going.</p>
<h2 id="stochastic-gradient-descent">Stochastic Gradient Descent</h2>
<p>SGD is probably the first optimization algorithm one thinks of. It’s
deceptively simple: Look around and take a step in the direction where the
gradient decreases the most. Once you’ve taken the step, <strong>Stop</strong>, look around
again, and repeat until you’re at the minima (the gradient is sufficiently
small or you come back to a point you’ve visited).</p>
<p>Th <em>S</em> in SGD comes from the fact that the gradient that the algorithm obtains
in practice is not perfect: it’s an approximation of the actual gradient of the
loss function, based on the batch of examples that are sampled. However, this
approximates the gradient reasonably well, and in the long run, the expected
path taken by this algorithm comes out to be the same as the path taken when we
can perfectly obtain the gradient.</p>
<p>The update rule for SGD is fairly simple:</p>
<p>$$\begin{align}
\theta_{t+1} &amp;\leftarrow \theta_{t} - \epsilon g(\theta_{t})
\end{align}$$</p>
<p>Combining this with a convergence criterion gives us the algorithm (implemented
in python here)</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;" tabindex="0"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">SGD</span>(L, G, p0, eps<span style="color:#f92672">=</span><span style="color:#ae81ff">5e-2</span>):
</span></span><span style="display:flex;"><span>    p <span style="color:#f92672">=</span> p0
</span></span><span style="display:flex;"><span>    g <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>inf
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">while</span> norm(g) <span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">5e-2</span>:
</span></span><span style="display:flex;"><span>        g <span style="color:#f92672">=</span> G(p)
</span></span><span style="display:flex;"><span>        p <span style="color:#f92672">=</span> p <span style="color:#f92672">-</span> eps<span style="color:#f92672">*</span>g
</span></span></code></pre></div><h2 id="sgd-with-momentum">SGD with Momentum</h2>
<p>While SGD is simple, it is slow to converge, taking several more steps than
required. This is because we come to a stop once we take a step, and the size
of the next step is solely determined by the gradient at that point. This means
that if we’re in a long stretch where the gradient is small, we can only
descend at the speed $\epsilon g$, even though we know that the stretch is
reasonably long. This slows down our algorithm and makes it take a longer time
to converge.</p>
<p>Momentum counters this by providing some inertia to the process. Intuitively,
if SGD is a person stopping and taking a step in the direction of maximum
descent, momentum is equivalent to throwing a ball down the incline of a given
mass and seeing where it settles. If you take a look at the path momentum
follows in the introduction plot, you can see that it doesn’t immediately stop
when it comes to a point with a zero (or very small) gradient; instead, it
oscillates until it loses all it’s velocity.</p>
<p>How do we simulate adding ‘mass’ to the update steps? We claim that the ball
moves at a velocity $v$, and model $v$ as an exponential moving average of the
current velocity and the gradient at the current point. The update equations
are as follows:</p>
<p>$$\begin{align}
v_{t+1} &amp;\leftarrow \alpha v_{t} - \epsilon g(\theta_{t}) \\
\theta_{t+1} &amp;\leftarrow \theta_{t} + v_{t+1}
\end{align}$$</p>
<p>What’s the maximum velocity we can move at? If all the gradients are in the
same direction for an infinite (practically a very large) period of time, then
this velocity is equal to</p>
<p>$$v_{\text{max}} = \frac{\epsilon g}{1-\alpha}$$</p>
<p>This can be derived by expanding out the recurrence in the update step, to
obtain an infinite GP. This GP converges when $\alpha &lt; 1$ to $1/(1-\alpha)$.
We can think of $1-\alpha$ as the ‘mass’ of the ball: the smaller this quantity
is, the faster the ball will move.</p>
<p>Generally (and in this simulation as well), $\alpha = 0.9$, so $1-\alpha = 0.1$.
This means that we can move atmost ten times faster than the step size at a
point, and this is what causes momentum to converge faster!</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;" tabindex="0"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">SGD_momentum</span>(L, G, p0, v0<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>, eps<span style="color:#f92672">=</span><span style="color:#ae81ff">5e-2</span>, a<span style="color:#f92672">=</span><span style="color:#ae81ff">0.9</span>):
</span></span><span style="display:flex;"><span>    p <span style="color:#f92672">=</span> p0
</span></span><span style="display:flex;"><span>    v <span style="color:#f92672">=</span> v0
</span></span><span style="display:flex;"><span>    g <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>inf
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">while</span> norm(g) <span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">5e-2</span>:
</span></span><span style="display:flex;"><span>        g <span style="color:#f92672">=</span> G(p)
</span></span><span style="display:flex;"><span>        v <span style="color:#f92672">=</span> a<span style="color:#f92672">*</span>v <span style="color:#f92672">-</span> eps<span style="color:#f92672">*</span>g
</span></span><span style="display:flex;"><span>        p <span style="color:#f92672">=</span> p <span style="color:#f92672">+</span> v
</span></span></code></pre></div><p>What do these gradient updates look like in practice? For starters, all changes
in the direction of the path are caused due to changes in the gradient. Where
the path takes a turn, the gradient is normal or antiparallel to the current
velocity, and at places where the path is straight, both the gradient and the
velocity are parallel. We can draw out the update vectors at two points in the
path above to see how this works.</p>
<iframe src="/articles/2023/res/momentum_vectors.html" style="width: 100%; height: 650px; border: 0"></iframe>
<h2 id="sgd-with-nesterov-momentum">SGD with Nesterov Momentum</h2>
<p>If you’ve seen the path that momentum takes, there is one issue: <em>Momentum
doesn’t stop very soon</em>. It’s easy to get the ball rolling, but harder to stop
it. This happens because the gradient that’s added to the path is the gradient
<em>at the current point</em>, not the gradient <em>at the point at which we would have
been, if we took the step</em>. In a continuous, real-world scenario, this
difference is infinitesimal, but in a numerical scenario, it becomes
significant if our step size is not small enough. This is also not an issue if
our gradients at consecutive points are similar, but becomes an issue if we
‘jump’ across a local minima: momentum would push us even further forward,
because the gradient at the current point is downward.</p>
<p>This ‘bug’ was discovered by Nesterov, and the fix was to compute the gradient
at $\theta_{t} + \alpha v_{t}$ (the position we will be at, if the gradient is
zero) rather than at $\theta_{t}$ (our current position). This ‘pulls’ the
gradient back if we jump across a minima</p>
<iframe src="/articles/2023/res/nesterov_comparision.html" style="width: 100%; height: 650px; border: 0"></iframe>
<p>The implementation and update are quite similar, with just a minor update to
the gradient calculation.</p>
<p>$$\begin{align}
v_{t+1} &amp;\leftarrow \alpha v_{t} - \epsilon g(\theta_{t} + \alpha v_{t}) \\
\theta_{t+1} &amp;\leftarrow \theta_{t} + v_{t+1}
\end{align}$$</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;" tabindex="0"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">SGD_nesterov</span>(L, G, p0, v0<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>, eps<span style="color:#f92672">=</span><span style="color:#ae81ff">1e-2</span>, a<span style="color:#f92672">=</span><span style="color:#ae81ff">0.9</span>):
</span></span><span style="display:flex;"><span>    p <span style="color:#f92672">=</span> p0
</span></span><span style="display:flex;"><span>    v <span style="color:#f92672">=</span> v0
</span></span><span style="display:flex;"><span>    g <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>inf
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">while</span> norm(g) <span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">5e-2</span>:
</span></span><span style="display:flex;"><span>        g <span style="color:#f92672">=</span> G(p <span style="color:#f92672">+</span> a<span style="color:#f92672">*</span>v)
</span></span><span style="display:flex;"><span>        v <span style="color:#f92672">=</span> a<span style="color:#f92672">*</span>v <span style="color:#f92672">-</span> eps<span style="color:#f92672">*</span>g
</span></span><span style="display:flex;"><span>        p <span style="color:#f92672">=</span> p <span style="color:#f92672">+</span> v
</span></span></code></pre></div><h2 id="gradient-descent-comparision">Putting it all together</h2>
<p>Here’s an interactive demo, showing the paths taken by SGD, SGD with Momentum
and SGD with Nesterov Updates. The arrows have the same colour scheme as
before, and show the directions in which the path is pulled (their sum is the
next resultant step). Playing around with this should give you an idea of how
these algorithms update themselves</p>
<iframe src="/articles/2023/res/comparision_plot.html" style="width: 100%; height: 650px; border: 0"></iframe>
<p>Even though there are a large number of new algorithms for optimization, SGD
with Nesterov momentum (along with Adam) remains the algorithm of choice for
training very large neural networks: it’s stable, explainable and converges
nicely.</p>
<!--
<h2 id="adaptive-optimizers">Adaptive Optimizers</h2>


<h2 id="adagrad">AdaGrad</h2>

$$\begin{align}
r_{t+1} &\leftarrow r_{t} + (g(\theta_{t}))^2 \\\\
v_{t+1} &\leftarrow -\frac{\epsilon g(\theta_{t})}{\sqrt{r_{t+1} + \delta}} \\\\
\theta_{t+1} &\leftarrow \theta_{t} + v_{t+1}
\end{align}$$

```python
def AdaGrad(L, G, p0, eps=5e-2):
    r = np.zeros(2)
    p = p0
    v = 0
    g = np.inf
    while norm(g) > 5e-2:
        g = G(p)
        r = r + g**2
        v = - ((eps)/np.sqrt(r))*g
        p = p + v
```

<h2 id="rmsprop">RMSProp</h2>

$$\begin{align}
r_{t+1} &\leftarrow \rho r_{t} + (1-\rho)(g(\theta_{t}))^2 \\\\
v_{t+1} &\leftarrow -\frac{\epsilon g(\theta_{t})}{\sqrt{r_{t+1} + \delta}} \\\\
\theta_{t+1} &\leftarrow \theta_{t} + v_{t+1}
\end{align}$$

```python
def RMSProp(L, G, p0, eps=1e-2, decay=0.9):
    r = np.zeros(2)
    p = p0
    v = 0
    g = np.inf
    while norm(g) > 5e-2:
        g = G(p)
        r = decay*r + (1-decay)*g**2
        v = - ((eps)/np.sqrt(r+1e-7))*g
        p = p + v
```

<h2 id="rmsprop-with-nesterov-momentum">RMSProp with Nesterov Momentum</h2>

$$\begin{align}
r_{t+1} &\leftarrow \rho r_{t} + (1-\rho)(g(\theta_{t} + \alpha v_{t}))^2 \\\\
v_{t+1} &\leftarrow \alpha v_{t} - \frac{\epsilon g(\theta_{t})}{\sqrt{r_{t+1} + \delta}} \\\\
\theta_{t+1} &\leftarrow \theta_{t} + v_{t+1}
\end{align}$$

```python
def RMSProp_nesterov(L, G, p0, eps=1e-2, decay=0.9, a=0.9):
    r = np.zeros(2)
    p = p0
    v = 0
    g = np.inf
    while norm(g) > 5e-2:
        g = G(p + a*v)
        r = decay*r + (1-decay)*g**2
        v = a*v - ((eps)/np.sqrt(r+1e-7))*g
        p = p + v
```

<h2 id="adam">Adam</h2>

```python
def Adam(L, G, p0, eps=1e-3, b1=0.9, b2=0.999):
    r = np.zeros(2)
    s = np.zeros(2)
    p = p0
    v = 0
    g = np.inf
    t = 0
    while norm(g) > 5e-2:
        g = G(p)
        t += 1
        s = b1*s + (1-b1)*g
        r = b2*r + (1-b2)*g**2
        sh = s/(1-b1**t)
        rh = r/(1-b2**t)
        v = - ((eps)/np.sqrt(rh+1e-7))*sh
        p = p + v
```

<h2 id="nadam-nesterov-adam">NAdam (Nesterov Adam)</h2>

```python
def NAdam(L, G, p0, eps=1e-3, b1=0.9, b2=0.999):
    r = np.zeros(2)
    s = np.zeros(2)
    p = p0
    v = 0
    g = np.inf
    t = 0
    while norm(g) > 5e-2:
        g = G(p)
        t += 1
        s = b1*s + (1-b1)*g
        r = b2*r + (1-b2)*g**2
        sh = b1*s/(1-b1**t) + (1-b1)*g/(1-b1**t) # nesterov step
        rh = r/(1-b2**t)
        v = - ((eps)/np.sqrt(rh+1e-7))*sh
        p = p + v
```

<h2 id="adamw">AdamW</h2>

```python
def AdamW(L, G, p0, eps=1e-3, b1=0.9, b2=0.999, l=1):
    r = np.zeros(2)
    s = np.zeros(2)
    p = p0
    v = 0
    g = np.inf
    t = 0
    while norm(g) > 5e-2:
        g = G(p)
        t += 1
        s = b1*s + (1-b1)*g
        r = b2*r + (1-b2)*g**2
        sh = s/(1-b1**t)
        rh = r/(1-b2**t)
        v = - ( ((eps)/np.sqrt(rh+1e-7))*sh + l*p ) # adamW step
        p = p + v
```

<h2 id="amsgrad">AMSGrad</h2>


<h2 id="adabound">AdaBound</h2>


<h2 id="adabelief">AdaBelief</h2>


<h1 id="second-order-optimizers">Second Order Optimizers</h1>


<h2 id="newton">Newton</h2>


<h2 id="conjugate-gradients">Conjugate Gradients</h2>


<h3 id="fletcher-reeves">Fletcher-Reeves</h3>


<h3 id="polak-ribiere">Polak-Ribiere</h3>


<h2 id="bfgs">BFGS</h2>


<h2 id="l-bfgs">L-BFGS</h2>-->
<h1 id="refs-and-footnotes">References and Footnotes</h1>
<ol>
<li>Goh, “Why Momentum Really Works”, Distill, 2017.
<a href="http://doi.org/10.23915/distill.00006">http://doi.org/10.23915/distill.00006</a></li>
<li>Goodfellow, Ian, Bengio, Yoshua and Courville, Aaron. Deep Learning. : MIT
Press, 2016.</li>
<li>Melville, James. Nesterov Accelerated Gradient and Momentum.
<a href="https://jlmelville.github.io/mize/nesterov.html">https://jlmelville.github.io/mize/nesterov.html</a></li>
</ol>
<hr/>
<p>This was supposed to also feature adaptive optimizers (AMSGrad, RMSProp, Adam
and friends), but due to CCIC happening in the last week of December, I didn’t
get the time to do this properly, and the second semester starts <strike>in a
couple days</strike> tomorrow, so hard deadline :/ I’ll try to get part 2 out
as soon as possible, but it might be a while. In the meantime, exploring the
source might help for the impatient.</p>
<p>For the complete code, and to play around and implement your own optimizers,
check out the repository here</p>
<center>
<a href="https://github.com/Aniruddha-Deb/optimizers"><img src="https://gh-card.dev/repos/Aniruddha-Deb/optimizers.svg"/></a>
</center>
</section>
<footer class="mt-12 flex flex-wrap">
<a class="mb-1.5 mr-1.5 rounded-lg bg-black/[3%] px-5 py-1.5 no-underline dark:bg-white/[8%]" href="https://aniruddhadeb.com/tags/programming">Programming</a>
<a class="mb-1.5 mr-1.5 rounded-lg bg-black/[3%] px-5 py-1.5 no-underline dark:bg-white/[8%]" href="https://aniruddhadeb.com/tags/machine-learning">Machine Learning</a>
<a class="mb-1.5 mr-1.5 rounded-lg bg-black/[3%] px-5 py-1.5 no-underline dark:bg-white/[8%]" href="https://aniruddhadeb.com/tags/deep-learning">Deep Learning</a>
</footer>
<nav class="mt-24 flex rounded-lg bg-black/[3%] text-lg dark:bg-white/[8%]">
<a class="flex w-1/2 items-center rounded-l-md p-6 pr-3 font-semibold no-underline hover:bg-black/[2%] dark:hover:bg-white/[3%]" href="https://aniruddhadeb.com/articles/2023/l2-regularization/"><span class="mr-1.5">←</span><span>L2 regularization intuition</span></a>
<a class="ml-auto flex w-1/2 items-center justify-end rounded-r-md p-6 pl-3 font-semibold no-underline hover:bg-black/[2%] dark:hover:bg-white/[3%]" href="https://aniruddhadeb.com/articles/2022/dl-workflow-2023/"><span>My DL workflow for 2023</span><span class="ml-1.5">→</span></a>
</nav>
<div class="mt-24" id="disqus_thread"></div>
<script>
    const disqusShortname = 'aniruddha-deb';
    const script = document.createElement('script');
    script.src = 'https://' + disqusShortname + '.disqus.com/embed.js';
    script.setAttribute('data-timestamp', +new Date());
    document.head.appendChild(script);
  </script>
</article>
</main>
<footer class="opaco mx-auto flex h-[4.5rem] max-w-4xl items-center px-8 text-[0.9em] opacity-60">
<div class="mr-auto">
    © 2023
    <a class="link" href="https://aniruddhadeb.com">Aniruddha Deb</a>
</div>
<a class="link mx-6" href="https://gohugo.io/" rel="noopener" target="_blank">Built with Hugo️️</a>️
  <a class="link" href="https://github.com/Aniruddha-Deb/hugo-paper" rel="noopener" target="_blank">✎ Paper</a>
</footer>
</body>
</html>
