
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="HandheldFriendly" content="True" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="robots" content="" />

  <link href="https://fonts.googleapis.com/css?family=Source+Code+Pro|Source+Sans+Pro:300,400,400i,700" rel="stylesheet">

    <link rel="stylesheet" type="text/css" href="https://aniruddhadeb.com/theme/stylesheet/style.min.css">

  <link rel="stylesheet" type="text/css" href="https://aniruddhadeb.com/theme/pygments/monokai.min.css">
  <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css">


    <link href="https://aniruddhadeb.com/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="Aniruddha Deb Atom">

    <link href="https://aniruddhadeb.com/feeds/all.rss.xml" type="application/rss+xml" rel="alternate" title="Aniruddha Deb RSS">


<!-- Google Analytics -->
<script type="text/javascript">
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-79245932-2', 'auto');
  ga('send', 'pageview');
</script>
<!-- End Google Analytics -->
<script>
MathJax = {
  tex: {
    inlineMath: [['$', '$'], ['\\(', '\\)']]
  },
  svg: {
    fontCache: 'global'
  }
};
</script>
<script src='https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js' type='text/javascript'></script>  

<meta name="author" content="Aniruddha Deb" />
<meta name="description" content="A nice intuition for L2 regularization comes from having a prior on the distribution of parameters: the prior assumes that the parameters are close to zero. Let&#39;s assume that the prior is $\mathcal{N}(0, \Sigma)$. The MAP estimate of the parameters would then be $$\begin{align} \theta_{\text{MAP …" />
<meta name="keywords" content="Mathematics, Machine Learning, Deep Learning">

<meta property="og:site_name" content="Aniruddha Deb"/>
<meta property="og:title" content="L2 regularization intuition"/>
<meta property="og:description" content="A nice intuition for L2 regularization comes from having a prior on the distribution of parameters: the prior assumes that the parameters are close to zero. Let&#39;s assume that the prior is $\mathcal{N}(0, \Sigma)$. The MAP estimate of the parameters would then be $$\begin{align} \theta_{\text{MAP …"/>
<meta property="og:locale" content="en_US"/>
<meta property="og:url" content="https://aniruddhadeb.com/articles/2023/l2-regularization.html"/>
<meta property="og:type" content="article"/>
<meta property="article:published_time" content="2023-01-22 10:20:00+05:30"/>
<meta property="article:modified_time" content=""/>
<meta property="article:author" content="https://aniruddhadeb.com/author/aniruddha-deb.html">
<meta property="article:section" content="Mathematics"/>
<meta property="article:tag" content="Mathematics"/>
<meta property="article:tag" content="Machine Learning"/>
<meta property="article:tag" content="Deep Learning"/>
<meta property="og:image" content="/extras/sitelogo.png">

  <title>Aniruddha Deb &ndash; L2 regularization intuition</title>

</head>
<body>
  <aside>
    <div>
      <a href="https://aniruddhadeb.com">
        <img src="/extras/sitelogo.png" alt="" title="">
      </a>
      <h1><a href="https://aniruddhadeb.com"></a></h1>


      <nav>
        <ul class="list">
          <li><a href="https://aniruddhadeb.com/pages/about.html#about">About</a></li>
          <li><a href="https://aniruddhadeb.com/pages/feeds.html#feeds">Feeds</a></li>

          <li><a href="/archives.html">archives</a></li>
          <li><a href="/categories">categories</a></li>
          <li><a href="/tags">tags</a></li>
          <li><a href="https://www.cse.iitd.ac.in/~cs1200869">website</a></li>
        </ul>
      </nav>

      <ul class="social">
        <li><a class="sc-github" href="https://www.github.com/Aniruddha-Deb" target="_blank"><i class="fab fa-github"></i></a></li>
        <li><a class="sc-stack-exchange" href="https://stackexchange.com/users/12827944/aniruddha-deb" target="_blank"><i class="fab fa-stack-exchange"></i></a></li>
        <li><a class="sc-goodreads-g" href="https://www.goodreads.com/aniruddhadeb" target="_blank"><i class="fab fa-goodreads-g"></i></a></li>
        <li><a class="sc-envelope-o" href="mailto:aniruddha.deb.2002@gmail.com" target="_blank"><i class="fas fa-envelope"></i></a></li>
      </ul>
    </div>


  </aside>
  <main>


<article class="single">
  <header>
      
    <h1 id="l2-regularization">L2 regularization intuition</h1>
    <p>
          Posted on Sun 22 January 2023 in <a href="https://aniruddhadeb.com/category/mathematics.html">Mathematics</a>


    </p>
  </header>


  <div>
    <p>A nice intuition for L2 regularization comes from having a prior on the
distribution of parameters: the prior assumes that the parameters are close to
zero. Let's assume that the prior is $\mathcal{N}(0, \Sigma)$. The MAP estimate
of the parameters would then be</p>
<p>$$\begin{align}
\theta_{\text{MAP}} &amp;= \text{argmax}_{\theta} \; P(\theta | D) \\
    &amp;= \text{argmax}_{\theta} \; P(D | \theta) P(\theta) \\
    &amp;= \text{argmax}_{\theta} \; \log P(D | \theta) + \log P(\theta)
\end{align}$$</p>
<p>$\log P(D | \theta)$ is simply the log-likelihood of the model, and optimizing
that would give you the MLE parameters. However, incorporating $\log P(\theta)$
gives us the L2 regularization parameter</p>
<p>$$\log P(\theta) = -\log((2\pi)^{n/2}|\Sigma|^{1/2}) - \frac{\theta^T \Sigma^{-1} \theta}{2}$$</p>
<p>The constant at the start goes out of the argmax, and we're left with the L2
regularization term. Taking a negative on both sides would give us the 
negative log-likelihood, which is the unregularized loss function. We'd then
minimize $\theta$. The net expression would look something like this:</p>
<p>$$\theta_{\text{MAP}} = \text{argmin}_{\theta} \; - P(\theta | D) + \frac{1}{2} \theta^T \Sigma^{-1} \theta$$</p>
<p>Regularization generally features a strength term $\lambda$: We can think of
$\lambda$ as being the inverse of every term in the diagonal of the covariance 
matrix (if it is a diagonal covariance matrix). We'd then get</p>
<p>$$\theta_{\text{MAP}} = \text{argmin}_{\theta} \; - P(\theta | D) + \frac{1}{2} \lambda\theta^T\theta$$</p>
<p>And this is the familiar L2 reglarized loss function.</p>
<hr>
<p>I got this from one of the <a href="https://www.cse.iitd.ac.in/~parags/teaching/col775/">Deep
Learning</a> lectures; it's a
nice treatment which I couldn't find in other places (maybe because I haven't
looked hard enough). Goodfellow certainly doesn't feature it though.</p>
  </div>
  <div class="tag-cloud">
    <p>
      <a href="https://aniruddhadeb.com/tag/mathematics.html">Mathematics</a>
      <a href="https://aniruddhadeb.com/tag/machine-learning.html">Machine Learning</a>
      <a href="https://aniruddhadeb.com/tag/deep-learning.html">Deep Learning</a>
    </p>
  </div>





<!-- Disqus -->
<div id="disqus_thread"></div>
<script type="text/javascript">
    var disqus_shortname = 'aniruddha-deb';
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<noscript>
        Please enable JavaScript to view comments.

</noscript>
<!-- End Disqus -->
</article>

    <footer>
<p>&copy;  </p>
<p>    Powered by <a href="http://getpelican.com" target="_blank">Pelican</a> - <a href="https://github.com/alexandrevicenzi/flex" target="_blank">Flex</a> theme by <a href="http://alexandrevicenzi.com" target="_blank">Alexandre Vicenzi</a>
</p>    </footer>
  </main>




<script type="application/ld+json">
{
  "@context" : "http://schema.org",
  "@type" : "Blog",
  "name": " Aniruddha Deb ",
  "url" : "https://aniruddhadeb.com",
  "image": "/extras/sitelogo.png",
  "description": ""
}
</script>

</body>
</html>