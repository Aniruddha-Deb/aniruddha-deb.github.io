<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Mathematics on Aniruddha Deb</title>
    <link>https://aniruddhadeb.com/categories/mathematics/</link>
    <description>Recent content in Mathematics on Aniruddha Deb</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 16 Feb 2023 16:00:00 +0000</lastBuildDate><atom:link href="https://aniruddhadeb.com/categories/mathematics/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Batch Normalization</title>
      <link>https://aniruddhadeb.com/articles/2023/batch-normalization/</link>
      <pubDate>Thu, 16 Feb 2023 16:00:00 +0000</pubDate>
      
      <guid>https://aniruddhadeb.com/articles/2023/batch-normalization/</guid>
      <description>$$ \require{physics} \newcommand{B}{\mathcal{B}}$$
Batch Normalization was proposed by Ioffe and Szegedy in 2015, and it spawned several normalization techniques that are used in SOTA models today (layer norm, weight norm, etc). Batch normalization normalizes the output of each layer based on the mean and variance of the examples in the current batch. Formally, if $\B = {x_1, \ldots, x_m}$ is our batch, then batch norm does the following transformation:
$$\begin{align} \mu_{\B} &amp;amp;= \frac{1}{m} \sum_i x_i \\ \sigma_{\B}^2 &amp;amp;= \left( \frac{1}{m} \sum_i x_i^2 \right) - \mu_{\B}^2 \\ \hat{x}_i &amp;amp;= \frac{x_i - \mu_{\B}}{\sqrt{\sigma^2_{\B} + \epsilon}} \\ y_i &amp;amp;= \gamma \hat{x}_i + \beta \end{align}$$</description>
    </item>
    
    <item>
      <title>L2 regularization intuition</title>
      <link>https://aniruddhadeb.com/articles/2023/l2-regularization/</link>
      <pubDate>Sun, 22 Jan 2023 10:15:00 +0000</pubDate>
      
      <guid>https://aniruddhadeb.com/articles/2023/l2-regularization/</guid>
      <description>A nice intuition for L2 regularization comes from having a prior on the distribution of parameters: the prior assumes that the parameters are close to zero. Let&amp;rsquo;s assume that the prior is $\mathcal{N}(0, \Sigma)$. The MAP estimate of the parameters would then be
$$\begin{align} \theta_{\text{MAP}} &amp;amp;= \text{argmax}_{\theta} ; P(\theta | D) \\ &amp;amp;= \text{argmax}_{\theta} ; P(D | \theta) P(\theta) \\ &amp;amp;= \text{argmax}_{\theta} ; \log P(D | \theta) + \log P(\theta) \end{align}$$</description>
    </item>
    
    <item>
      <title>Filtrations</title>
      <link>https://aniruddhadeb.com/articles/2022/filtrations/</link>
      <pubDate>Mon, 28 Nov 2022 03:00:00 +0000</pubDate>
      
      <guid>https://aniruddhadeb.com/articles/2022/filtrations/</guid>
      <description>Recap If you remember the note on random variables, then this picks up exactly where that left off. $\newcommand{\triple}{(\Omega, \mathcal{F}, \mathbf{P})}$$\newcommand{\P}{\mathbf{P}}$
Definition 1.1: A Measurable space $(X,\Sigma)$ consists of a set $X$ and a $\sigma$-algebra $\Sigma$ defined on $X$.
Recall that a $\sigma$-algebra is simply a collection of subsets over $X$ that is closed over unions, intersections and complements.
Definition 1.2: If $\mathcal{A}$ and $\mathcal{B}$ are $\sigma$-algebras defined on $\Omega$ and $\mathcal{B} \subseteq \mathcal{A}$, then $\mathcal{B}$ is a sub $\sigma$-algebra of $\mathcal{A}$</description>
    </item>
    
    <item>
      <title>A Note on Conditional Probability</title>
      <link>https://aniruddhadeb.com/articles/2021/note-on-conditional-probability/</link>
      <pubDate>Sat, 25 Dec 2021 15:20:00 +0000</pubDate>
      
      <guid>https://aniruddhadeb.com/articles/2021/note-on-conditional-probability/</guid>
      <description>$\newcommand{\cE}[2]{\mathbf{E}(#1\ |\ #2)}$$\newcommand{\cP}[2]{\mathbf{P}(#1\ |\ #2)}$$\renewcommand{\P}[1]{\mathbf{P}(#1)}$$\newcommand{\E}[1]{\mathbf{E}(#1)}$$\newcommand{\F}{\mathcal{F}}$$\newcommand{\G}{\mathcal{G}}$$\newcommand{\ind}[1]{\mathbf{1}_{#1}}$ To motivate this note, I’ll pose the following problem:
Consider $X \sim \text{Uniform}([0,1])$. What is $\cP{X &amp;gt; \frac{1}{2}}{X \in \mathbb{Q}}$ ?
At first glance, the answer seems simple: it’s 1/2! Closer inspection reveals that the event $X \in \mathbb{Q}$ is not measurable: the rationals have measure zero, hence from our high-school (perhaps even undergraduate) definition of conditional probability, the given probability should be undefined. However, the conditional probability does exist, and it equals 1/2.</description>
    </item>
    
    <item>
      <title>A Note on Random Variables</title>
      <link>https://aniruddhadeb.com/articles/2021/note-on-random-variables/</link>
      <pubDate>Fri, 03 Dec 2021 21:00:00 +0000</pubDate>
      
      <guid>https://aniruddhadeb.com/articles/2021/note-on-random-variables/</guid>
      <description>$\newcommand{\triple}{(\Omega, \mathcal{F}, \mathbf{P})}$$\newcommand{\P}{\mathbf{P}}$ This note on random variables follows as a result of confusing notation in several math textbooks. I&amp;rsquo;ll explain random variables (in measure theoretic terms) as verbosely as I can, and then prove some results. This article assumes that the reader is familiar with probability triples $\triple$, as well as a basic idea of what random variables are, in non-measure theory terms.
1. Random Variable Prerequisites We start with defining measurable spaces and measurable functions</description>
    </item>
    
    <item>
      <title>Function transforms (providing a broader picture of Laplace Transforms)</title>
      <link>https://aniruddhadeb.com/articles/2021/function-transforms/</link>
      <pubDate>Wed, 12 May 2021 18:00:00 +0000</pubDate>
      
      <guid>https://aniruddhadeb.com/articles/2021/function-transforms/</guid>
      <description>I&amp;rsquo;ll begin this article by brushing up a few definitions:
A function is a mapping between two sets: the domain D and the codomain C.
It&amp;rsquo;s very important to note here that the function is the mapping itself, and not an element in the codomain or the domain. The function operates on an element in the domain to give an element in the codomain. Formally, we would write this function as $f:D \to C$</description>
    </item>
    
    <item>
      <title>Understanding Jacobians</title>
      <link>https://aniruddhadeb.com/articles/2021/understanding-jacobians/</link>
      <pubDate>Fri, 29 Jan 2021 15:11:00 +0000</pubDate>
      
      <guid>https://aniruddhadeb.com/articles/2021/understanding-jacobians/</guid>
      <description>$\newcommand{\pdv}[2]{\frac{\partial{#1}}{\partial{#2}}}$ $\newcommand{\ah}{\pmb{a} + \pmb{h}}$ $\newcommand{\a}{\pmb{a}}$ $\newcommand{\h}{\pmb{h}}$
The Jacobian Matrix Consider a function that maps reals to reals, $f:\Bbb{R} \to \Bbb{R}$. The linear approximation of this function is given by $$f(a+h) \approx f(a) + hf&amp;rsquo;(a)$$ This is pretty simple to do, and follows from taylor&amp;rsquo;s expansion upto the first order.
Let&amp;rsquo;s try expanding this concept to vector spaces. For a function $f:\Bbb{R}^n \to \Bbb{R}$, it&amp;rsquo;s linear approximation is given by $$f(\pmb{a} + \pmb{h}) \approx f(\pmb{a}) + \pmb{h}\cdot\nabla{f}(\a)$$ (bold type indicates vectors).</description>
    </item>
    
    <item>
      <title>Math Notes: Lagrange interpolation</title>
      <link>https://aniruddhadeb.com/articles/2020/math-notes-1/</link>
      <pubDate>Fri, 14 Aug 2020 17:37:00 +0000</pubDate>
      
      <guid>https://aniruddhadeb.com/articles/2020/math-notes-1/</guid>
      <description>This is a small set of posts that come into the category of &amp;ldquo;notes&amp;rdquo;: self-explanations of concepts that I have recently picked up and found interesting.
Lagrange Interpolation Lagrange Interpolation is a concept that allows us to find a polynomial of least degree passing through a given set of points. Specifically:
If $S = {(x_i, y_i) : x_i, y_i \in R, 1 \lt i \le n}$, then the polynomial of least degree passing through all the points in $S$ is given by $$P(x) = \sum_{i=1}^n L_i(x) \cdot y_i$$ where $$L_i(x) = \frac{(x-x_1)(x-x_2)&amp;hellip;(x-x_{i-1})(x-x_{i+1})&amp;hellip;(x-x_n)} {(x_i-x_1)(x_i-x_2)&amp;hellip;(x_i-x_{i-1})(x_i-x_{i+1})&amp;hellip;(x_i-x_n)}$$ or simply, $$P(x) = \sum_{i=1}^n \frac{\prod_{r \ne i}(x-x_r)}{\prod_{r \ne i}{(x_i-x_r)}} \cdot y_i$$ note that the degree of polynomial $P &amp;lt; n$.</description>
    </item>
    
    <item>
      <title>Is the shortest solution to a problem the best?</title>
      <link>https://aniruddhadeb.com/articles/2020/shortest-solution-best-or-not/</link>
      <pubDate>Sun, 26 Jul 2020 21:00:00 +0000</pubDate>
      
      <guid>https://aniruddhadeb.com/articles/2020/shortest-solution-best-or-not/</guid>
      <description>My old man always used to say that there are two ways to solve a problem: there&amp;rsquo;s the horse way, and there&amp;rsquo;s the donkey way. The donkey way involves tedious calculations, whereas the horse way &amp;lsquo;cuts&amp;rsquo; through the problem. Take this problem as an example:
For each positive integer $n$, let $$y_n = ((n+1)(n+2)&amp;hellip;(n+n))^\frac1n$$ for $x \in \mathbb{R}$. Let $[x]$ be the greatest integer less than or equal to $x$. If $\lim_{n \to \infty} y_n = L$, then the value of $[L]$ is ______ ?</description>
    </item>
    
    <item>
      <title>ISC 2020 Analysis: An application of Data Science and Statistics</title>
      <link>https://aniruddhadeb.com/articles/2020/isc-2020-analysis/</link>
      <pubDate>Sat, 11 Jul 2020 16:30:00 +0000</pubDate>
      
      <guid>https://aniruddhadeb.com/articles/2020/isc-2020-analysis/</guid>
      <description>The ISC Exam results were released on 10th June, 3 PM IST. In this article, I&amp;rsquo;ll be analyzing the results of the 117 students in the science stream of my school and showing how they performed. I&amp;rsquo;ll also weave a story with the data and point out things that could have been improved, which would be helpful for future students.
Index: Elementary inferences: How have people fared overall? Frequency Distribution of Marks: How many people got the same marks in a subject?</description>
    </item>
    
    <item>
      <title>Solving the African Integral (from YG file cover)</title>
      <link>https://aniruddhadeb.com/articles/2020/african-integral/</link>
      <pubDate>Thu, 09 Jul 2020 20:30:00 +0000</pubDate>
      
      <guid>https://aniruddhadeb.com/articles/2020/african-integral/</guid>
      <description>A long time ago, I gave my friend (Let&amp;rsquo;s call him C) an integral to solve. He came back to me a few days later and the conversation went something like this:
C: Debu, I couldn&amp;rsquo;t solve that African integral you gave me.
Me: Ok, but why are you calling it African?
C: Because Africa is a really big continent, y&amp;rsquo;know?
Me: Ok, but isn&amp;rsquo;t Asia bigger?
C: Debu, please stop making me feel dumb</description>
    </item>
    
    <item>
      <title>A Compilation of hard limits</title>
      <link>https://aniruddhadeb.com/articles/2020/hard-limits/</link>
      <pubDate>Fri, 05 Jun 2020 11:30:00 +0000</pubDate>
      
      <guid>https://aniruddhadeb.com/articles/2020/hard-limits/</guid>
      <description>This list consists of the limits that I found most challenging.
$$\lim_{n \to \infty} \left( \frac{n!}{n^n} \right) ^\frac 1n$$ $$\lim_{x \to 0} \left( \frac{1}{\ln(x + \sqrt{x^2+1})} - \frac 1{\ln(x+1)} \right)$$ $$\lim_{n \to \infty} \frac{n + n^2 + n^3 + &amp;hellip; + n^n}{1^n + 2^n + 3^n + &amp;hellip; + n^n}$$ $$\lim_{n \to \infty} \left( \frac{n^n(x+n)\left(x+\frac n2\right)&amp;hellip;\left(x+\frac nn\right)}{n!(x^2+n^2)\left(x^2+\frac {n^2}{4}\right)&amp;hellip;\left( x^2 + \frac{n^2}{n^2}\right)}\right)^{\frac x n}$$ $$\lim_{x \to 0} \left( 1^{\sin^{-2}x} + 2^{\sin^{-2}x} + &amp;hellip; + n^{\sin^{-2}x}\right)^{\sin^2 x}$$ $$\lim_{n \to \infty} \sqrt[\leftroot{-2}\uproot{2}n+1]{(n+1)!</description>
    </item>
    
    <item>
      <title>Limit involving higher order infinitesimals</title>
      <link>https://aniruddhadeb.com/articles/2020/limit-higher-order-infinitesimals/</link>
      <pubDate>Fri, 05 Jun 2020 07:30:00 +0000</pubDate>
      
      <guid>https://aniruddhadeb.com/articles/2020/limit-higher-order-infinitesimals/</guid>
      <description>Simple limit problems consist of the form $\lim_{x \to 0}\frac{O_1(x)O_2(x)..}{O_a(x)O_b(x)..}$, such as $\lim_{x \to 0} \frac{\sin 3x \tan 2x \tan^{-1} 5x}{x^2 \ln(1+x)}$. Here, the infinitesimals are well defined and cancel out easily. Some trickier limit problems involve the difference of two infinitesimals. A good example is $\lim_{t \to 0} \frac{\sin t - \tan t}{t^3}$. These kind of problems require expansions to solve them cleanly. L&amp;rsquo;Hopital rule is tedious as it will need to be repeated atleast thrice for this given limit, which involves infinitesimals of order 3.</description>
    </item>
    
    <item>
      <title>No square ends in 3</title>
      <link>https://aniruddhadeb.com/articles/2020/no-square-ends-in-3/</link>
      <pubDate>Fri, 15 May 2020 11:30:00 +0000</pubDate>
      
      <guid>https://aniruddhadeb.com/articles/2020/no-square-ends-in-3/</guid>
      <description>This is an interesting number theory fact that seems strange when taken at face value. Here&amp;rsquo;s a small proof of it:</description>
    </item>
    
    <item>
      <title>Roots of f(f(..f(x)..)), f(x) = ax² &#43; bx &#43; c</title>
      <link>https://aniruddhadeb.com/articles/2020/roots-of-fffx/</link>
      <pubDate>Thu, 30 Apr 2020 20:30:00 +0000</pubDate>
      
      <guid>https://aniruddhadeb.com/articles/2020/roots-of-fffx/</guid>
      <description>Define $ f(x) = ax^2 + bx + c , a,b,c \in \mathbb{R}$ and $ f^n(x) = f(f^{n-1}(x)), n&amp;gt;1 $. Prove that the real roots of $ f^n(x) $ are symmetric about the vertical line passing through vertex i.e. $ x = \frac{-b}{2a} $
This seems like a complicated problem. Let&amp;rsquo;s start by first making intuitional sense of this problem. We can say that $ f^n(x) $ will be a polynomial of the order $ 2^n $ and will have as many roots.</description>
    </item>
    
    <item>
      <title>An integral involving ζ(2) (And Euler&#39;s first proof for the Basel Problem)</title>
      <link>https://aniruddhadeb.com/articles/2020/zeta-2-integral/</link>
      <pubDate>Wed, 29 Apr 2020 22:30:00 +0000</pubDate>
      
      <guid>https://aniruddhadeb.com/articles/2020/zeta-2-integral/</guid>
      <description>Evaluate the integral $$\int_0^1 \frac{\log(x)}{x-1}dx$$
There are a few methods of doing this: the first one uses the taylor series expansion of \( \log(1-x) \): $$I = -\int_0^1 \frac{\log(1-x)}{x}dx$$ $$I = \int_0^1 \frac 1x \left( x + \frac{x^2}{2} + \frac{x^3}{3} + &amp;hellip; \right) $$
This expression nicely integrates to give $$I = 1 + \frac{1}{2^2} + \frac{1}{3^2} + &amp;hellip; = \boxed{\frac{\pi^2}{6}}$$
The last step here involves the summation \( \zeta(2) = \sum_{k=1}^{\infty} \frac 1 {k^2} = \frac{\pi^2}{6}\).</description>
    </item>
    
    <item>
      <title>ICSE Mathematics - Last 23 years analysis and 2018 forecast</title>
      <link>https://aniruddhadeb.com/articles/2018/icse-mathematics-analysis/</link>
      <pubDate>Tue, 09 Jan 2018 10:30:00 +0000</pubDate>
      
      <guid>https://aniruddhadeb.com/articles/2018/icse-mathematics-analysis/</guid>
      <description>A speculative format for the 2018 ICSE Mathematics paper, created by analysis of the mathematics question papers of the past 23 years. &lt;img src=&#34;https://aniruddhadeb.com/articles/2018/res/icse_math_analysis.png&#34; alt=&#34;Analysis results&#34;&gt;</description>
    </item>
    
  </channel>
</rss>
